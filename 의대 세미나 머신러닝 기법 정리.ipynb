{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective of the notebook\n",
    "\n",
    "이 노트는 아래 두 논문에서 사용된 머신러닝 기법에 대한 설명이다.\n",
    "1. Development of a Claims based Frailty Indicator\n",
    "2. Development and validation of a Hospital Frailty Risk Score focusing on older people in acute care settings using electronic hospital records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 논문에 대한 설명은 경상대학교 대학원 정보통계학과 서성효(박사과정)의 [github](https://github.com/sung-hyo/Paper-Review)에서 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model\n",
    "1. Development of a Claims based Frailty Indicator    \n",
    "    - **logistic regression with lasso penalty**\n",
    "    - **random forests**\n",
    "    - **gradient boosting**\n",
    "\n",
    "\n",
    "2. Development and validation of a Hospital Frailty Risk Score focusing on older people in acute care settings using electronic hospital records    \n",
    "    - **k-means clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 logistic regression with lasso penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ordinary Least Squares**\n",
    "\n",
    "target(반응변수)과 예측값 사이의 잔차의 제곱을 최소화하는 $w = (w_1, ..., w_p)$ 계수(parameter)를 훈련시키는 모델이다.\n",
    "\n",
    "$$\\min_{w} {|| X w - y||_2}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "---\n",
    " 일반적인 회귀 분석과 마찬가지로 종속변수(target)와 독립변수(feature)간의 관계를 구체적인 함수로 나타내여 향후 예측에 사용하는 것이다. 독립변수의 선형 결합을 통해 종속변수를 설명한다는 점은 유사하지만 종속변수가 범주형 변수일 때 사용한다는 점, 분류기법(이항, 다항)이라는 점이 기존 선형 회귀 분석과의 차이점이며 의료, 통신 등 전반에 다양한 분류 및 예측을 위한 모델로서 폭넓게 사용하고있다.\n",
    " \n",
    " 로지스틱 함수(logistic function)는 아래 그림과 같으며 입력 t에 대해서 0과 1사이의 값을 출력한다. 로지스틱 함수 $\\sigma(t)$는 아래와 같다.\n",
    "\n",
    "![formular](https://render.githubusercontent.com/render/math?math=%5Csigma%20%28t%29%3D%7B%5Cfrac%20%7Be%5E%7Bt%7D%7D%7Be%5E%7Bt%7D%2B1%7D%7D%3D%7B%5Cfrac%20%7B1%7D%7B1%2Be%5E%7B-t%7D%7D%7D&mode=display)\n",
    " \n",
    "\n",
    " \n",
    "![logistic](logistic.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) penalty란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적인 최소제곱법(Ordinary Least Squares)은 훈련시 계수가 커지면서 일반화 능력이 떨어지는데 이를 방지하기 위해서 penalty를 부여한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 Ordinary Least Squares의 계수의 크기(parameter)에 페널티를 부여함으로써 계수의 크기가 커지는것을 억제한다.    \n",
    "기계학습에서는 이를 가중치 감쇠, 규제 등의 용어로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*일반화 능력이란?*\n",
    "\n",
    "![일반화 능력](패널티.png)\n",
    "\n",
    "특정 데이터에만 잘 적용되는게 아니라 유사한 데이터에서도 적용될 수 있다는 것을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) penalty의 종류\n",
    "\n",
    "1. Ridge regression($L2$-norm)\n",
    "\n",
    "2. Lasso regression($L1$-norm)\n",
    "\n",
    "두 regression은 parameter(계수)의 벡터에 대한 거리($L2$-norm, $L1$-norm)를 penalty로 가진다.\n",
    "\n",
    "이를 통해 Ordinary Least Squares의 계수의 크기(parameter)에 penalty를 부여함으로써 계수의 크기가 커지는것을 억제한다.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge Regression**\n",
    "\n",
    "$$\\min_{w} {{|| X w - y||_2}^2 + \\alpha {||w||_2}^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso Regression**\n",
    "\n",
    "$$\\min_{w} {||X w - y||_2 ^ 2 + \\alpha ||w||_1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식들은 패널티항을 가지고 잔차 제곱합을 최소화한다.($\\alpha$는 패널티의 크기를 제어하는 매개 변수이다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge Regression vs. Lasso Regression**\n",
    "\n",
    "Ridge Regression은 계수를 작게는 하지만 0이 되지는 않은 반면에, Lasso Regression은 0이 되는 계수가 많아진다.\n",
    "따라서 Lasso Regression를 사용하게 되면 0이 아닌 항만 남게되므로 변수 선택(특징 추출)을 효과를 가지게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 random forests, gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forests, gradient boosting 두 기법은 Ensemble methods(앙상블 방법)이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble methods(앙상블 방법)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블 방법은 여러 예측기가 출력한 복수의 예측값을 적절한 방법으로 결합하여 더 높은 정확도의 예측값을 출력한다.\n",
    "\n",
    "**생물 정보학, 의학 등 데이터를 충분히 수집하기 어려운 분야에서 앙상블 방법을 통해 데이터양에 따른 어려움을 극복할 수 있다.(배깅, 부스팅)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 앙상블 방법은 일반적으로 두 가지로 구분할 수 있다 : averaging method, boosting method    \n",
    "    1. averaging method : 여러개 추정량을 독립적으로 구축한 다음 예측치를 평균화하는 것이다.(Bagging, random forests)    \n",
    "    2. boosting method : 여러 가지 약한 모델을 결합하여 강력한 앙상블을 제작하는 것이다.(AdaBoost, gradient boosting)\n",
    "    \n",
    "- bagging(bootstrap aggregating) : bootstrap sample을 이용하여 만든 여러개의 모델을 결합하는 방법.\n",
    "    - bootstrapping : 데이터를 복원추출하여 여러 개의 sample들을 만드는 방법.\n",
    "\n",
    "\n",
    "- boosting : bagging과 유사하게 데이터에서 sample을 추출하여 여러 개의 모델을 생성하는 기법 중 하나지만, 가장 큰 차이점은 순차적(Sequential)방법이라는 것이다. \n",
    "    \n",
    "    bagging의 경우 각각의 모델들이 학습시에 상호 영향을 주지 않고, 학습이 끝난 다음 그 결과를 종합하는 기법이었다면,  \n",
    "    boosting은 이전 모델의 학습을 토대로 다음 모델의 학습 데이터의 sample이 뽑힐 가중치를 조정하여 학습을 진행하는 방법이다.\n",
    "\n",
    "    예를 들어, Boosting은 A 분류기를 만든 후, 그 정보를 바탕으로 B 분류기를 만들고, 다시 그 정보를 바탕으로 C 분류기를 만든다. 최종적으로 만들어진 분류기들을 모두 결합하여 최종 모델을 만드는 과정을 순차적으로 실행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![앙상블](Ensemble.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 앙상블 방법 중 DecisionTree(의사결정나무)에 대한 random forests, gradient boosting에 대해 설명하고자 한다.\n",
    "\n",
    "DecisionTree(의사결정나무)에 대해서 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 의사결정나무(DecisionTree)\n",
    "\n",
    "의사 결정 규칙을 학습하여 대상 변수의 값을 예측하는 모델이다.    \n",
    "여러 변수 중 하나를 선택하여 그 변수에 대한 기준값(threshold)을 정하여 구분하는데 이를 분류 규칙(분할기준)이라고 한다.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쉽게 말해 스무고개와 비슷하다고 생각할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![결정트리](결정트리.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 장점 : 결과가 해석가능한 모델이다(White Box)\n",
    "\n",
    "- 단점 : 불안정성(데이터에 따라 결과가 매우 달라진다)    \n",
    "    이러한 단점을 보완하기 위해 RandomForest를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomForest**\n",
    "\n",
    "같은 데이터에 대해 의사결정나무를 여러 개 만들어(Forest) 그 결과를 종합해 예측 성능을 높이는 기법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 개의 의사결정나무(DecisionTree)를 만들때 bootstrapping를 이용한 데이터를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![랜덤포레스트](randomforest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gradient boosting**\n",
    "\n",
    "여러개의 의사결정나무(DecisionTree)를 묶어 강력한 모델을 만드는 또 다른 앙상블 기법이다.\n",
    "\n",
    "랜덤포레스트와 달리 이전 의사결정나무(DecisionTree)의 오차를 보완하는 방식으로 순차적 Tree를 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![그래디언트부스팅](gradientboosting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 군집화 : 주어진 데이터들의 특성을 고려해 데이터 집단(Cluster)을 정의하는 작업이다.\n",
    "\n",
    "![clustering](https://notebooks.azure.com/sunghyo-seo/libraries/open-project/raw/cluster_1.png)\n",
    "\n",
    "* K-Means clustering \n",
    "    1. k개 군집 중심의 초기값을 준다.\n",
    "    2. 샘플들을 가장 가까운 중심에 배정한다.\n",
    "    3. 배정된 값들끼리 평균으로 군집 중심을 갱신한다. \n",
    "    4. 2~3 과정을 반복하다 배정된 값들이 전에 배정된 값들과 차이가 없으면 수렴한 것으로 판단하고 군집화를 종료한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
